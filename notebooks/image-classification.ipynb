{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Federated Learning: Image Classification\n",
    "\n",
    "In their recent (and exteremly thorough!) review of the federated learning literature [*Kairouz, et al (2019)*](https://arxiv.org/pdf/1912.04977.pdf) define federated learning as a machine learning setting where multiple entities (clients) collaborate in solving a machine learning problem, under the coordination of a central server or service provider. Each client’s raw data is stored locally and not exchanged or transferred; instead, focused updates intended for immediate aggregation are used to achieve the learning objective.\n",
    "\n",
    "In this tutorial we will use a federated version of the classic MNIST dataset to introduce the Federated Learning (FL) API layer of TensorFlow Federated (TFF), [`tff.learning`](https://www.tensorflow.org/federated/api_docs/python/tff/learning) - a set of high-level interfaces that can be used to perform common types of federated learning tasks, such as federated training, against user-supplied models implemented in TensorFlow or Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "import typing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required to run TFF inside Jupyter notebooks\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.federated_computation(lambda: 'Hello, World!')()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data\n",
    "\n",
    "In the IID setting the local data on each \"client\" is assumed to be a representative sample of the global data distribution. This is typically the case by construction when performing data parallel training of deep learning models across multiple CPU/GPU \"clients\".\n",
    "\n",
    "The non-IID case is significantly more complicated as there are many ways in which data can be non-IID and different degress of \"non-IIDness\". Consider a supervised task with features $X$ and labels $y$. A statistical model of federated learning involves two levels of sampling:\n",
    "\n",
    "1. Sampling a client $i$ from the distribution over available clients $Q$\n",
    "2. Sampling an example $(X,y)$ from that client’s local data distribution $P_i(X,y)$.\n",
    "\n",
    "Non-IID data in federated learning typically refers to differences between $P_i$ and $P_j$ for different clients $i$ and $j$. However, it is worth remembering that both the distribution of available clients, $Q$, and the distribution of local data for client $i$, $P_i$, may change over time which introduces another dimension of “non-IIDness”. Finally, if the local data on a client's device is insufficiently randomized, perhaps ordered by time, then independence is violated locally as well. \n",
    "\n",
    "In order to facilitate experimentation TFF includes federated versions of several popular datasets that exhibit different forms and degrees of non-IIDness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What datasets are available?\n",
    "tff.simulation.datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial uses a version of MNIST that contains a version of the original NIST dataset that has been re-processed using [LEAF](https://leaf.cmu.edu/) so that the data is keyed by the original writer of the digits. \n",
    "\n",
    "The federated MNIST dataset displays a particular type of non-IIDness: feature distribution skew (covariate shift). Whith feature distribution skew the marginal distributions $P_i(X)$ vary across clients, even though $P(y|X)$ is shared. In the federated MNIST dataset users are writing the same numbers but each user has a different writing style characterized but different stroke width, slant, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.simulation.datasets.emnist.load_data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emnist_train, emnist_test = (tff.simulation\n",
    "                                .datasets\n",
    "                                .emnist\n",
    "                                .load_data(only_digits=True, cache_dir=\"../data\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_CLIENTS = len(emnist_train.client_ids)\n",
    "NUMBER_CLIENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_client_ids(client_ids: typing.List[str],\n",
    "                      sample_size: typing.Union[float, int],\n",
    "                      random_state: np.random.RandomState) -> typing.List[str]:\n",
    "    \"\"\"Randomly selects a subset of clients ids.\"\"\"\n",
    "    number_clients = len(client_ids)\n",
    "    error_msg = \"'client_ids' must be non-emtpy.\"\n",
    "    assert number_clients > 0, error_msg\n",
    "    if isinstance(sample_size, float):\n",
    "        error_msg = \"Sample size must be between 0 and 1.\"\n",
    "        assert 0 <= sample_size <= 1, error_msg\n",
    "        size = int(sample_size * number_clients)\n",
    "    elif isinstance(sample_size, int):\n",
    "        error_msg = f\"Sample size must be between 0 and {number_clients}.\"\n",
    "        assert 0 <= sample_size <= number_clients, error_msg\n",
    "        size = sample_size\n",
    "    else:\n",
    "        error_msg = \"Type of 'sample_size' must be 'float' or 'int'.\"\n",
    "        raise TypeError(error_msg)\n",
    "    random_idxs = random_state.randint(number_clients, size=size)\n",
    "    return [client_ids[i] for i in random_idxs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are what the client ids look like\n",
    "_random_state = np.random.RandomState(42)\n",
    "sample_client_ids(emnist_train.client_ids, 10, _random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_datasets(source: tff.simulation.ClientData,\n",
    "                       client_ids: typing.Union[None, typing.List[str]]) -> typing.Dict[str, tf.data.Dataset]:\n",
    "    \"\"\"Create tf.data.Dataset instances for clients using their client_id.\"\"\"\n",
    "    if client_ids is None:\n",
    "        client_ids = source.client_ids\n",
    "    datasets = {client_id: source.create_tf_dataset_for_client(client_id) for client_id in client_ids}\n",
    "    return datasets\n",
    "\n",
    "\n",
    "def sample_client_datasets(source: tff.simulation.ClientData,\n",
    "                           sample_size: typing.Union[float, int],\n",
    "                           random_state: np.random.RandomState) -> typing.Dict[str, tf.data.Dataset]:\n",
    "    \"\"\"Randomly selects a subset of client datasets.\"\"\"\n",
    "    client_ids = sample_client_ids(source.client_ids, sample_size, random_state)\n",
    "    client_datasets = create_tf_datasets(source, client_ids)\n",
    "    return client_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_random_state = np.random.RandomState()\n",
    "client_datasets = sample_client_datasets(emnist_train, sample_size=1, random_state=_random_state)\n",
    "(client_id, client_dataset), *_ = client_datasets.items()\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(12,6), sharex=True, sharey=True)\n",
    "for i, example in enumerate(client_dataset.take(5)):\n",
    "    axes[i].imshow(example[\"pixels\"].numpy(), cmap=\"gray\")\n",
    "    axes[i].set_title(example[\"label\"].numpy())\n",
    "_ = fig.suptitle(x= 0.5, y=0.75, t=f\"Training examples for a client {client_id}\", fontsize=15)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "\n",
    "Since each client dataset is already a [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset), preprocessing can be accomplished using Dataset transformations. Another option would be to use preprocessing operations from [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
    "\n",
    "Preprocessing consists of the following steps:\n",
    "\n",
    "1. `map` a function that flattens the 28 x 28 images into 784-element tensors\n",
    "2. `map` a function that rename the features from pixels and label to X and y for use with Keras\n",
    "3. `shuffle` the individual examples\n",
    "4. `batch` the into training batches\n",
    "\n",
    "We also throw in a `repeat` over the data set to run several epochs on each client device before sending parameters to the server for averaging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = (tf.data\n",
    "              .experimental\n",
    "              .AUTOTUNE)\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "NUMBER_TRAINING_EPOCHS = 5 # number of local updates!\n",
    "TRAINING_BATCH_SIZE = 32\n",
    "TESTING_BATCH_SIZE = 32\n",
    "\n",
    "NUMBER_FEATURES = 28 * 28\n",
    "NUMBER_TARGETS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reshape(training_batch):\n",
    "    \"\"\"Extracts and reshapes data from a training sample \"\"\"\n",
    "    pixels = training_batch[\"pixels\"]\n",
    "    label = training_batch[\"label\"]\n",
    "    X = tf.reshape(pixels, shape=[-1]) # flattens 2D pixels to 1D\n",
    "    y = tf.reshape(label, shape=[1])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def create_training_dataset(client_dataset: tf.data.Dataset) -> tf.data.Dataset:\n",
    "    \"\"\"Create a training dataset for a client from a raw client dataset.\"\"\"\n",
    "    training_dataset = (client_dataset.map(_reshape, num_parallel_calls=AUTOTUNE)\n",
    "                                      .shuffle(SHUFFLE_BUFFER_SIZE, seed=None, reshuffle_each_iteration=True)\n",
    "                                      .repeat(NUMBER_TRAINING_EPOCHS)\n",
    "                                      .batch(TRAINING_BATCH_SIZE)\n",
    "                                      .prefetch(buffer_size=AUTOTUNE))\n",
    "    return training_dataset\n",
    "\n",
    "\n",
    "def create_testing_dataset(client_dataset: tf.data.Dataset) -> tf.data.Dataset:\n",
    "    \"\"\"Create a testing dataset for a client from a raw client dataset.\"\"\"\n",
    "    testing_dataset = (client_dataset.map(_reshape, num_parallel_calls=AUTOTUNE)\n",
    "                                     .batch(TESTING_BATCH_SIZE))\n",
    "    return testing_dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to choose the clients included in each training round\n",
    "\n",
    "In a typical federated training scenario there will be a very large population of user devices however only a fraction of these devices are likely to be available for training at a given point in time. For example, if the client devices are mobile phones then they might only participate in training when plugged into a power source, off a metered network, and otherwise idle.\n",
    "\n",
    "In a simulated environment, where all data is locally available, an approach is to simply sample a random subset of the clients to be involved in each round of training so that the subset of clients involved will vary from round to round.\n",
    "\n",
    "### How many clients to include in each round?\n",
    "\n",
    "Updating and averaging a larger number of client models per training round yields better convergence and in a simulated training environment probably makes sense to include as many clients as is computationally feasible. However in real-world training scenario while averaging a larger number of clients improve convergence, it also makes training vulnerable to slowdown due to unpredictable tail delays in computation/communication at/with the clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_federated_data(training_source: tff.simulation.ClientData,\n",
    "                          testing_source: tff.simulation.ClientData,\n",
    "                          sample_size: typing.Union[float, int],\n",
    "                          random_state: np.random.RandomState) -> typing.Dict[str, typing.Tuple[tf.data.Dataset, tf.data.Dataset]]:\n",
    "    \n",
    "    # sample clients ids from the training dataset\n",
    "    client_ids = sample_client_ids(training_source.client_ids, sample_size, random_state)\n",
    "    \n",
    "    federated_data = {}\n",
    "    for client_id in client_ids:\n",
    "        # create training dataset for the client\n",
    "        _tf_dataset = training_source.create_tf_dataset_for_client(client_id)\n",
    "        training_dataset = create_training_dataset(_tf_dataset)\n",
    "        \n",
    "        # create the testing dataset for the client\n",
    "        _tf_dataset = testing_source.create_tf_dataset_for_client(client_id)\n",
    "        testing_dataset = create_testing_dataset(_tf_dataset)\n",
    "        \n",
    "        federated_data[client_id] = (training_dataset, testing_dataset)\n",
    "    \n",
    "    return federated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_random_state = np.random.RandomState(42)\n",
    "federated_data = create_federated_data(emnist_train,\n",
    "                                       emnist_test,\n",
    "                                       sample_size=0.01,\n",
    "                                       random_state=_random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keys are client ids, values are (training_dataset, testing_dataset) pairs\n",
    "len(federated_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a model with Keras\n",
    "\n",
    "If you are using Keras, you likely already have code that constructs a Keras model. Since the model will need to be replicated on each of the client devices we wrap the model in a no-argument Python function, a representation of which, will eventually be invoked on each client to create the model on that client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model_fn() -> keras.Model:\n",
    "    model_fn = keras.models.Sequential([\n",
    "      keras.layers.Input(shape=(NUMBER_FEATURES,)),\n",
    "      keras.layers.Dense(units=NUMBER_TARGETS),\n",
    "      keras.layers.Softmax(),\n",
    "    ])\n",
    "    return model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use any model with TFF, it needs to be wrapped in an instance of the [`tff.learning.Model`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model) interface, which exposes methods to stamp the model's forward pass, metadata properties, etc, and also introduces additional elements such as ways to control the process of computing federated metrics. \n",
    "\n",
    "Once you have a Keras model like the one we've just defined above, you can have TFF wrap it for you by invoking [`tff.learning.from_keras_model`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/from_keras_model), passing the model and a sample data batch as arguments, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.learning.from_keras_model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tff_model_fn() -> tff.learning.Model:\n",
    "    keras_model = create_keras_model_fn()\n",
    "    dummy_batch = (tf.constant(0.0, shape=(TRAINING_BATCH_SIZE, NUMBER_FEATURES), dtype=tf.float32),\n",
    "                   tf.constant(0, shape=(TRAINING_BATCH_SIZE, 1), dtype=tf.int32))\n",
    "    loss_fn = (keras.losses\n",
    "                    .SparseCategoricalCrossentropy())\n",
    "    metrics = [\n",
    "        keras.metrics.SparseCategoricalAccuracy()\n",
    "    ]\n",
    "    tff_model_fn = (tff.learning\n",
    "                       .from_keras_model(keras_model, dummy_batch, loss_fn, None, metrics))\n",
    "    return tff_model_fn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, since our model will need to be replicated on each of the client devices we wrap the model in a no-argument Python function, a representation of which, will eventually be invoked on each client to create the model on that client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model on federated data\n",
    "\n",
    "Now that we have a model wrapped as `tff.learning.Model` for use with TFF, we can let TFF construct a Federated Averaging algorithm by invoking the helper function `tff.learning.build_federated_averaging_process` as follows.\n",
    "\n",
    "Keep in mind that the argument needs to be a constructor (such as `create_tff_model_fn` above), not an already-constructed instance, so that the construction of your model can happen in a context controlled by TFF.\n",
    "\n",
    "One critical note on the Federated Averaging algorithm below, there are 2 optimizers: a \n",
    "\n",
    "1. `client_optimizer_fn` which is only used to compute local model updates on each client. \n",
    "2. `server_optimizer_fn` applies the averaged update to the global model on the server. \n",
    "\n",
    "N.B. the choice of optimizer and learning rate may need to be different than those you would use to train the model on a standard i.i.d. dataset. Start with stochastic gradient descent with a smaller (than normal) learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.learning.build_federated_averaging_process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_LEARNING_RATE = 1e-2\n",
    "SERVER_LEARNING_RATE = 1e0\n",
    "\n",
    "\n",
    "def create_client_optimizer(learning_rate: float = CLIENT_LEARNING_RATE,\n",
    "                            momentum: float = 0.0,\n",
    "                            nesterov: bool = False) -> keras.optimizers.Optimizer:\n",
    "    client_optimizer = (keras.optimizers\n",
    "                             .SGD(learning_rate, momentum, nesterov))\n",
    "    return client_optimizer\n",
    "\n",
    "\n",
    "def create_server_optimizer(learning_rate: float = SERVER_LEARNING_RATE,\n",
    "                            momentum: float = 0.0,\n",
    "                            nesterov: bool = False) -> keras.optimizers.Optimizer:\n",
    "    server_optimizer = (keras.optimizers\n",
    "                             .SGD(learning_rate, momentum, nesterov))\n",
    "    return server_optimizer\n",
    "\n",
    "\n",
    "federated_averaging_process = (tff.learning\n",
    "                                  .build_federated_averaging_process(create_tff_model_fn, \n",
    "                                                                     create_client_optimizer,\n",
    "                                                                     create_server_optimizer,\n",
    "                                                                     client_weight_fn=None,\n",
    "                                                                     stateful_delta_aggregate_fn=None,\n",
    "                                                                     stateful_model_broadcast_fn=None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What just happened? TFF has constructed a pair of *federated computations* (i.e., programs in TFF's internal glue language) and packaged them into a [`tff.utils.IterativeProcess`](https://www.tensorflow.org/federated/api_docs/python/tff/utils/IterativeProcess) in which these computations are available as a pair of properties `initialize` and `next`.\n",
    "\n",
    "It is a goal of TFF to define computations in a way that they could be executed in real federated learning settings, but currently only local execution simulation runtime is implemented. To execute a computation in a simulator, you simply invoke it like a Python function. This default interpreted environment is not designed for high performance, but it will suffice for this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## `initialize`\n",
    "\n",
    "A function that takes no arguments and returns the state of the federated averaging process on the server. This function is only called to initialize a federated averaging process after it has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# () -> SERVER_STATE\n",
    "print(federated_averaging_process.initialize.type_signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = federated_averaging_process.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `next`\n",
    "\n",
    "A function that takes current server state and federated data as arguments and returns the updated server state as well as any training metrics. Calling `next` performs a single round of federated averaging consisting of the following steps.\n",
    "\n",
    "1. pushing the server state (including the model parameters) to the clients\n",
    "2. on-device training on their local data\n",
    "3. collecting and averaging model updates\n",
    "4. producing a new updated model at the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the training datasets from the federated data\n",
    "federated_training_data = [training_dataset for _, (training_dataset, _) in federated_data.items()]\n",
    "\n",
    "# SERVER_STATE, FEDERATED_DATA -> SERVER_STATE, TRAINING_METRICS\n",
    "state, metrics = federated_averaging_process.next(state, federated_training_data)\n",
    "print(f\"round: 0, metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a few more rounds on the same training data (which will over-fit to a particular set of clients but will converge faster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_training_rounds = 15\n",
    "for n in range(1, number_training_rounds):\n",
    "    state, metrics = federated_averaging_process.next(state, federated_training_data)\n",
    "    print(f\"round:{n}, metrics:{metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First attempt at simulating federated averaging\n",
    "\n",
    "A proper federated averaging simulation would randomly sample new clients for each training round, allow for evaluation of training progress on training and testing data, and log training and testing metrics to TensorBoard for reference.\n",
    "\n",
    "Here we define a function that randomly sample new clients prior to each training round and logs training metrics TensorBoard. We defer handling testing data until we discuss federated evaluation towards the end of the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_federated_averaging(federated_averaging_process: tff.utils.IterativeProcess,\n",
    "                                 training_source: tff.simulation.ClientData,\n",
    "                                 testing_source: tff.simulation.ClientData,\n",
    "                                 sample_size: typing.Union[float, int],\n",
    "                                 random_state: np.random.RandomState,\n",
    "                                 number_rounds: int,\n",
    "                                 initial_state: None = None,\n",
    "                                 tensorboard_logging_dir: str = None):\n",
    "    \n",
    "    state = federated_averaging_process.initialize() if initial_state is None else initial_state\n",
    "    \n",
    "    if tensorboard_logging_dir is not None:\n",
    "        \n",
    "        if not os.path.isdir(tensorboard_logging_dir):\n",
    "            os.makedirs(tensorboard_logging_dir)\n",
    "\n",
    "        summary_writer = (tf.summary\n",
    "                            .create_file_writer(tensorboard_logging_dir))\n",
    "\n",
    "        with summary_writer.as_default():\n",
    "            for n in range(number_rounds):\n",
    "                federated_data = create_federated_data(training_source,\n",
    "                                                       testing_source,\n",
    "                                                       sample_size,\n",
    "                                                       random_state)\n",
    "                anonymized_training_data = [dataset for _, (dataset, _) in federated_data.items()]\n",
    "                state, metrics = federated_averaging_process.next(state, anonymized_training_data)\n",
    "                print(f\"Round: {n}, Training metrics: {metrics}\")\n",
    "\n",
    "                for name, value in metrics._asdict().items():\n",
    "                    tf.summary.scalar(name, value, step=n)          \n",
    "    else:\n",
    "        for n in range(number_rounds):\n",
    "            federated_data = create_federated_data(training_source,\n",
    "                                                   testing_source,\n",
    "                                                   sample_size,\n",
    "                                                   random_state)\n",
    "            anonymized_training_data = [dataset for _, (dataset, _) in federated_data.items()]\n",
    "            state, metrics = federated_averaging_process.next(state, anonymized_training_data)\n",
    "            print(f\"Round: {n}, Training metrics: {metrics}\")\n",
    "    \n",
    "    return state, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_averaging_process = (tff.learning\n",
    "                                  .build_federated_averaging_process(create_tff_model_fn, \n",
    "                                                                     create_client_optimizer,\n",
    "                                                                     create_server_optimizer,\n",
    "                                                                     client_weight_fn=None,\n",
    "                                                                     stateful_delta_aggregate_fn=None,\n",
    "                                                                     stateful_model_broadcast_fn=None))\n",
    "_random_state = np.random.RandomState(42)\n",
    "_tensorboard_logging_dir = \"../results/logs/tensorboard\"\n",
    "updated_state, current_metrics = simulate_federated_averaging(federated_averaging_process,\n",
    "                                                              training_source=emnist_train,\n",
    "                                                              testing_source=emnist_test,\n",
    "                                                              sample_size=0.01,\n",
    "                                                              random_state=_random_state,\n",
    "                                                              number_rounds=5,\n",
    "                                                              tensorboard_logging_dir=_tensorboard_logging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customizing the model implementation\n",
    "\n",
    "Keras is the recommended high-level model API for TensorFlow and you should be using Keras models and creating TFF models using [`tff.learning.from_keras_model`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/from_keras_model) whenever possible.\n",
    "\n",
    "However, [`tff.learning`](https://www.tensorflow.org/federated/api_docs/python/tff/learning) provides a lower-level model interface, [`tff.learning.Model`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/Model), that exposes the minimal functionality necessary for using a model for federated learning. Directly implementing this interface (possibly still using building blocks from [`keras`](https://www.tensorflow.org/guide/keras)) allows for maximum customization without modifying the internals of the federated learning algorithms.\n",
    "\n",
    "Now we are going to repeat the above from scratch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining model variables\n",
    "\n",
    "We start by defining a new Python class that inherits from `tff.learning.Model`. In the class constructor (i.e., the `__init__` method) we will initialize all relevant variables using TF primatives as well as define the our \"input spec\" which defines the shape and types of the tensors that will hold input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tff.learning.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        # initialize some trainable variables\n",
    "        self._weights = tf.Variable(\n",
    "            initial_value=lambda: tf.zeros(dtype=tf.float32, shape=(NUMBER_FEATURES, NUMBER_TARGETS)),\n",
    "            name=\"weights\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self._bias = tf.Variable(\n",
    "            initial_value=lambda: tf.zeros(dtype=tf.float32, shape=(NUMBER_TARGETS,)),\n",
    "            name=\"bias\",\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # initialize some variables used in computing metrics\n",
    "        self._number_examples = tf.Variable(0.0, name='number_examples', trainable=False)\n",
    "        self._total_loss = tf.Variable(0.0, name='total_loss', trainable=False)\n",
    "        self._number_true_positives = tf.Variable(0.0, name='number_true_positives', trainable=False)\n",
    "        \n",
    "        # define the input spec\n",
    "        self._input_spec = collections.OrderedDict([\n",
    "            ('X', tf.TensorSpec([None, NUMBER_FEATURES], tf.float32)),\n",
    "            ('y', tf.TensorSpec([None, 1], tf.int32))\n",
    "        ])\n",
    "\n",
    "    @property\n",
    "    def input_spec(self):\n",
    "        return self._input_spec\n",
    "    \n",
    "    @property\n",
    "    def local_variables(self):\n",
    "        return [self._number_examples, self._total_loss, self._number_true_positives]\n",
    "\n",
    "    @property\n",
    "    def non_trainable_variables(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def trainable_variables(self):\n",
    "        return [self._weights, self._bias]\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the forward pass\n",
    "\n",
    "With the variables for model parameters and cumulative statistics in place we can now define the `forward_pass` method that computes loss, makes predictions, and updates the cumulative statistics for a single batch of input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tff.learning.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        # initialize some trainable variables\n",
    "        self._weights = tf.Variable(\n",
    "            initial_value=lambda: tf.zeros(dtype=tf.float32, shape=(NUMBER_FEATURES, NUMBER_TARGETS)),\n",
    "            name=\"weights\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self._bias = tf.Variable(\n",
    "            initial_value=lambda: tf.zeros(dtype=tf.float32, shape=(NUMBER_TARGETS,)),\n",
    "            name=\"bias\",\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # initialize some variables used in computing metrics\n",
    "        self._number_examples = tf.Variable(0.0, name='number_examples', trainable=False)\n",
    "        self._total_loss = tf.Variable(0.0, name='total_loss', trainable=False)\n",
    "        self._number_true_positives = tf.Variable(0.0, name='number_true_positives', trainable=False)\n",
    "        \n",
    "        # define the input spec\n",
    "        self._input_spec = collections.OrderedDict([\n",
    "            ('X', tf.TensorSpec([None, NUMBER_FEATURES], tf.float32)),\n",
    "            ('y', tf.TensorSpec([None, 1], tf.int32))\n",
    "        ])\n",
    "\n",
    "    @property\n",
    "    def input_spec(self):\n",
    "        return self._input_spec\n",
    "    \n",
    "    @property\n",
    "    def local_variables(self):\n",
    "        return [self._number_examples, self._total_loss, self._number_true_positives]\n",
    "\n",
    "    @property\n",
    "    def non_trainable_variables(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def trainable_variables(self):\n",
    "        return [self._weights, self._bias]\n",
    "\n",
    "    @tf.function\n",
    "    def _count_true_positives(self, y_true, y_pred):\n",
    "        return tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n",
    "\n",
    "    @tf.function\n",
    "    def _linear_transformation(self, batch):\n",
    "        X = batch['X']\n",
    "        W, b = self.trainable_variables\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        return Z\n",
    "    \n",
    "    @tf.function\n",
    "    def _loss_fn(self, y_true, probabilities):\n",
    "        return -tf.reduce_mean(tf.reduce_sum(tf.one_hot(y_true, NUMBER_TARGETS) * tf.math.log(probabilities), axis=1))\n",
    "    \n",
    "    @tf.function\n",
    "    def _model_fn(self, batch):\n",
    "        Z = self._linear_transformation(batch)\n",
    "        probabilities = tf.nn.softmax(Z)\n",
    "        return probabilities\n",
    "    \n",
    "    @tf.function\n",
    "    def forward_pass(self, batch, training=True):\n",
    "        probabilities = self._model_fn(batch)\n",
    "        y_pred = tf.argmax(probabilities, axis=1, output_type=tf.int32)\n",
    "        y_true = tf.reshape(batch['y'], shape=[-1])\n",
    "\n",
    "        # compute local variables\n",
    "        loss = self._loss_fn(y_true, probabilities)\n",
    "        true_positives = self._count_true_positives(y_true, y_pred)\n",
    "        number_examples = tf.size(y_true, out_type=tf.float32)\n",
    "        \n",
    "        # update local variables\n",
    "        self._total_loss.assign_add(loss)\n",
    "        self._number_true_positives.assign_add(true_positives)\n",
    "        self._number_examples.assign_add(number_examples)\n",
    "\n",
    "        batch_output = tff.learning.BatchOutput(\n",
    "            loss=loss,\n",
    "            predictions=y_pred,\n",
    "            num_examples=tf.cast(number_examples, tf.int32)\n",
    "        )\n",
    "        return batch_output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the local metrics\n",
    "\n",
    "Next, we define a method `report_local_outputs` that returns a set of local metrics. These are the values, in addition to model updates (which are handled automatically), that are eligible to be aggregated to the server in a federated learning or evaluation process.\n",
    "\n",
    "Finally, we need to determine how to aggregate the local metrics emitted by each device by defining `federated_output_computation`. This is the only part of the code that isn't written in TensorFlow - it's a federated computation expressed in TFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTModel(tff.learning.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        # initialize some trainable variables\n",
    "        self._weights = tf.Variable(\n",
    "            initial_value=lambda: tf.zeros(dtype=tf.float32, shape=(NUMBER_FEATURES, NUMBER_TARGETS)),\n",
    "            name=\"weights\",\n",
    "            trainable=True\n",
    "        )\n",
    "        self._bias = tf.Variable(\n",
    "            initial_value=lambda: tf.zeros(dtype=tf.float32, shape=(NUMBER_TARGETS,)),\n",
    "            name=\"bias\",\n",
    "            trainable=True\n",
    "        )\n",
    "        \n",
    "        # initialize some variables used in computing metrics\n",
    "        self._number_examples = tf.Variable(0.0, name='number_examples', trainable=False)\n",
    "        self._total_loss = tf.Variable(0.0, name='total_loss', trainable=False)\n",
    "        self._number_true_positives = tf.Variable(0.0, name='number_true_positives', trainable=False)\n",
    "        \n",
    "        # define the input spec\n",
    "        self._input_spec = collections.OrderedDict([\n",
    "            ('X', tf.TensorSpec([None, NUMBER_FEATURES], tf.float32)),\n",
    "            ('y', tf.TensorSpec([None, 1], tf.int32))\n",
    "        ])\n",
    "\n",
    "    @property\n",
    "    def federated_output_computation(self):\n",
    "        return self._aggregate_metrics_across_clients\n",
    "    \n",
    "    @property\n",
    "    def input_spec(self):\n",
    "        return self._input_spec\n",
    "    \n",
    "    @property\n",
    "    def local_variables(self):\n",
    "        return [self._number_examples, self._total_loss, self._number_true_positives]\n",
    "\n",
    "    @property\n",
    "    def non_trainable_variables(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def trainable_variables(self):\n",
    "        return [self._weights, self._bias]\n",
    "    \n",
    "    @tff.federated_computation\n",
    "    def _aggregate_metrics_across_clients(metrics):\n",
    "        aggregated_metrics = {\n",
    "            'number_examples': tff.federated_sum(metrics.number_examples),\n",
    "            'average_loss': tff.federated_mean(metrics.average_loss, metrics.number_examples),\n",
    "            'accuracy': tff.federated_mean(metrics.accuracy, metrics.number_examples)\n",
    "        }\n",
    "        return aggregated_metrics\n",
    "\n",
    "    @tf.function\n",
    "    def _count_true_positives(self, y_true, y_pred):\n",
    "        return tf.reduce_sum(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n",
    "\n",
    "    @tf.function\n",
    "    def _linear_transformation(self, batch):\n",
    "        X = batch['X']\n",
    "        W, b = self.trainable_variables\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        return Z\n",
    "    \n",
    "    @tf.function\n",
    "    def _loss_fn(self, y_true, probabilities):\n",
    "        return -tf.reduce_mean(tf.reduce_sum(tf.one_hot(y_true, NUMBER_TARGETS) * tf.math.log(probabilities), axis=1))\n",
    "    \n",
    "    @tf.function\n",
    "    def _model_fn(self, batch):\n",
    "        Z = self._linear_transformation(batch)\n",
    "        probabilities = tf.nn.softmax(Z)\n",
    "        return probabilities\n",
    "    \n",
    "    @tf.function\n",
    "    def forward_pass(self, batch, training=True):\n",
    "        probabilities = self._model_fn(batch)\n",
    "        y_pred = tf.argmax(probabilities, axis=1, output_type=tf.int32)\n",
    "        y_true = tf.reshape(batch['y'], shape=[-1])\n",
    "\n",
    "        # compute local variables\n",
    "        loss = self._loss_fn(y_true, probabilities)\n",
    "        true_positives = self._count_true_positives(y_true, y_pred)\n",
    "        number_examples = tf.cast(tf.size(y_true), tf.float32)\n",
    "        \n",
    "        # update local variables\n",
    "        self._total_loss.assign_add(loss)\n",
    "        self._number_true_positives.assign_add(true_positives)\n",
    "        self._number_examples.assign_add(number_examples)\n",
    "\n",
    "        batch_output = tff.learning.BatchOutput(\n",
    "            loss=loss,\n",
    "            predictions=y_pred,\n",
    "            num_examples=tf.cast(number_examples, tf.int32)\n",
    "        )\n",
    "        return batch_output\n",
    "\n",
    "    @tf.function\n",
    "    def report_local_outputs(self):\n",
    "        local_metrics = collections.OrderedDict([\n",
    "            ('number_examples', self._number_examples),\n",
    "            ('average_loss', self._total_loss / self._number_examples),\n",
    "            ('accuracy', self._number_true_positives / self._number_examples)\n",
    "        ])\n",
    "        return local_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are a few points worth highlighting:\n",
    "\n",
    "* All state that your model will use must be captured as TensorFlow variables, as TFF does not use Python at runtime (remember your code should be written such that it can be deployed to mobile devices).\n",
    "* Your model should describe what form of data it accepts (input_spec), as in general, TFF is a strongly-typed environment and wants to determine type signatures for all components. Declaring the format of your model's input is an essential part of it.\n",
    "* Although technically not required, we recommend wrapping all TensorFlow logic (forward pass, metric calculations, etc.) as tf.functions, as this helps ensure the TensorFlow can be serialized, and removes the need for explicit control dependencies.\n",
    "\n",
    "The above is sufficient for evaluation and algorithms like Federated SGD. However, for Federated Averaging, we need to specify how the model should train locally on each batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTrainableModel(MNISTModel, tff.learning.TrainableModel):\n",
    "    \n",
    "    def __init__(self, optimizer):\n",
    "        super().__init__()\n",
    "        self._optimizer = optimizer\n",
    "\n",
    "    @tf.function\n",
    "    def train_on_batch(self, batch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            output = self.forward_pass(batch)\n",
    "        gradients = tape.gradient(output.loss, self.trainable_variables)\n",
    "        self._optimizer.apply_gradients(zip(tf.nest.flatten(gradients), tf.nest.flatten(self.trainable_variables)))\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulating federated training with the new model\n",
    "\n",
    "With all the above in place, the remainder of the process looks like what we've seen already - just replace the model constructor with the constructor of our new model class, and use the two federated computations in the iterative process you created to cycle through training rounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_tff_model_fn():\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=0.02)\n",
    "    return MNISTrainableModel(optimizer)\n",
    "    \n",
    "federated_averaging_process = (tff.learning\n",
    "                                  .build_federated_averaging_process(create_custom_tff_model_fn))\n",
    "\n",
    "_random_state = np.random.RandomState(42)\n",
    "updated_state, current_metrics = simulate_federated_averaging(federated_averaging_process,\n",
    "                                                              training_source=emnist_train,\n",
    "                                                              testing_source=emnist_test,\n",
    "                                                              sample_size=0.01,\n",
    "                                                              random_state=_random_state,\n",
    "                                                              number_rounds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "All of our experiments so far presented only federated training metrics - the average metrics over all batches of data trained across all clients in the round. Should we be concerened about overfitting? Yes! In federated averaging algorithms there are two different ways to over-fit. \n",
    "\n",
    "1. Overfitting the shared model (especially if we use the same set of clients on each round).\n",
    "2. Over-ftting local models on the clients.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated evaluation\n",
    "\n",
    "To perform evaluation on federated data, you can construct another federated computation designed for just this purpose, using the [`tff.learning.build_federated_evaluation`](https://www.tensorflow.org/federated/api_docs/python/tff/learning/build_federated_evaluation) function, and passing in your model constructor as an argument. Note that evaluation doesn't perform gradient descent and there's no need to construct optimizers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tff.learning.build_federated_evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_evaluation = (tff.learning\n",
    "                          .build_federated_evaluation(create_custom_tff_model_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function type signature: SERVER_MODEL, FEDERATED_DATA -> METRICS\n",
    "print(federate_evaluation.type_signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `federated_evaluation` function is similar to `tff.utils.IterativeProcess.next` but with two important differences. \n",
    "\n",
    "1. Function does not return the server state; since evaluation doesn't modify the model or any other aspect of state - you can think of it as stateless.\n",
    "2. Function only needs the model and doesn't require any other part of server state that might be associated with training, such as optimizer variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics = federated_evaluation(updated_state.model, federated_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the numbers may look marginally better than what was reported by the last round of training. By convention, the training metrics reported by the iterative training process generally reflect the performance of the model at the beginning of the training round, so the evaluation metrics will always be one step ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating on client data not used in training\n",
    "\n",
    "Since we are training a shared model for digit classication we might also want to evaluate the performance of the model on client test datasets where the corresponding training dataset was not used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_random_state = np.random.RandomState(42)\n",
    "client_datasets = sample_client_datasets(emnist_test, sample_size=0.01, random_state=_random_state)\n",
    "federated_testing_data = [create_testing_dataset(client_dataset) for _, client_dataset in client_datasets.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_metrics = federated_evaluation(updated_state.model, federated_testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding evaluation to our federated averaging simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_federated_averaging(federated_averaging_process: tff.utils.IterativeProcess,\n",
    "                                 federated_evaluation,\n",
    "                                 training_source: tff.simulation.ClientData,\n",
    "                                 testing_source: tff.simulation.ClientData,\n",
    "                                 sample_size: typing.Union[float, int],\n",
    "                                 random_state: np.random.RandomState,\n",
    "                                 number_rounds: int,\n",
    "                                 tensorboard_logging_dir: str = None):\n",
    "    \n",
    "    state = federated_averaging_process.initialize()\n",
    "    \n",
    "    if tensorboard_logging_dir is not None:\n",
    "        \n",
    "        if not os.path.isdir(tensorboard_logging_dir):\n",
    "            os.makedirs(tensorboard_logging_dir)\n",
    "\n",
    "        summary_writer = (tf.summary\n",
    "                            .create_file_writer(tensorboard_logging_dir))\n",
    "\n",
    "        with summary_writer.as_default():\n",
    "            for n in range(number_rounds):\n",
    "                federated_data = create_federated_data(training_source,\n",
    "                                                       testing_source,\n",
    "                                                       sample_size,\n",
    "                                                       random_state)\n",
    "                \n",
    "                # extract the training and testing datasets\n",
    "                anonymized_training_data = []\n",
    "                anonymized_testing_data = []\n",
    "                for training_dataset, testing_dataset in federated_data.values():\n",
    "                    anonymized_training_data.append(training_dataset)\n",
    "                    anonymized_testing_data.append(testing_dataset)\n",
    "        \n",
    "                state, _ = federated_averaging_process.next(state, anonymized_training_data)\n",
    "                training_metrics = federated_evaluation(state.model, anonymized_training_data)\n",
    "                testing_metrics = federated_evaluation(state.model, anonymized_testing_data)\n",
    "                print(f\"Round: {n}, Training metrics: {training_metrics}, Testing metrics: {testing_metrics}\")\n",
    "\n",
    "                # tensorboard logging\n",
    "                for name, value in training_metrics._asdict().items():\n",
    "                    tf.summary.scalar(name, value, step=n)\n",
    "                \n",
    "                for name, value in testing_metrics._asdict().items():\n",
    "                    tf.summary.scalar(name, value, step=n)\n",
    "    else:\n",
    "        for n in range(number_rounds):\n",
    "            federated_data = create_federated_data(training_source,\n",
    "                                                       testing_source,\n",
    "                                                       sample_size,\n",
    "                                                       random_state)\n",
    "                \n",
    "            # extract the training and testing datasets\n",
    "            anonymized_training_data = []\n",
    "            anonymized_testing_data = []\n",
    "            for training_dataset, testing_dataset in federated_data.values():\n",
    "                anonymized_training_data.append(training_dataset)\n",
    "                anonymized_testing_data.append(testing_dataset)\n",
    "\n",
    "            state, _ = federated_averaging_process.next(state, anonymized_training_data)\n",
    "            training_metrics = federated_evaluation(state.model, anonymized_training_data)\n",
    "            testing_metrics = federated_evaluation(state.model, anonymized_testing_data)\n",
    "            print(f\"Round: {n}, Training metrics: {training_metrics}, Testing metrics: {testing_metrics}\")\n",
    "    \n",
    "    return state, (training_metrics, testing_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "federated_averaging_process = (tff.learning\n",
    "                                  .build_federated_averaging_process(create_tff_model_fn, \n",
    "                                                                     create_client_optimizer,\n",
    "                                                                     create_server_optimizer,\n",
    "                                                                     client_weight_fn=None,\n",
    "                                                                     stateful_delta_aggregate_fn=None,\n",
    "                                                                     stateful_model_broadcast_fn=None))\n",
    "\n",
    "federated_evaluation = (tff.learning\n",
    "                           .build_federated_evaluation(create_tff_model_fn))\n",
    "\n",
    "_random_state = np.random.RandomState(42)\n",
    "updated_state, current_metrics = simulate_federated_averaging(federated_averaging_process,\n",
    "                                                              federated_evaluation,\n",
    "                                                              training_source=emnist_train,\n",
    "                                                              testing_source=emnist_test,\n",
    "                                                              sample_size=0.01,\n",
    "                                                              random_state=_random_state,\n",
    "                                                              number_rounds=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interesting resources\n",
    "\n",
    "[PySyft](https://github.com/OpenMined/PySyft) is a Python library for secure and private Deep Learning created by [OpenMined](https://www.openmined.org/). PySyft decouples private data from model training, using\n",
    "[Federated Learning](https://ai.googleblog.com/2017/04/federated-learning-collaborative.html),\n",
    "[Differential Privacy](https://en.wikipedia.org/wiki/Differential_privacy),\n",
    "and [Multi-Party Computation (MPC)](https://en.wikipedia.org/wiki/Secure_multi-party_computation) within the main Deep Learning frameworks like PyTorch and TensorFlow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
