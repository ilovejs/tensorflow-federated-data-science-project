{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import functools\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow_federated as tff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a pre-trained model\n",
    "\n",
    "We load a model that was pre-trained following the TensorFlow tutorial Text generation using a RNN with eager execution. However, rather than training on The Complete Works of Shakespeare, we pre-trained the model on the text from the Charles Dickens' A Tale of Two Cities and A Christmas Carol.\n",
    "\n",
    "Other than expanding the vocabularly, we didn't modify the original tutorial, so this initial model isn't state-of-the-art, but it produces reasonable predictions and is sufficient for our tutorial purposes. The final model was saved with tf.keras.models.save_model(include_optimizer=False).\n",
    "\n",
    "We will use federated learning to fine-tune this model for Shakespeare in this tutorial, using a federated version of the data provided by TFF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A fixed vocabularly of ASCII chars that occur in the works of Shakespeare and Dickens:\n",
    "vocabulary = list('dhlptx@DHLPTX $(,048cgkoswCGKOSW[_#\\'/37;?bfjnrvzBFJNRVZ\"&*.26:\\naeimquyAEIMQUY]!%)-159\\r')\n",
    "\n",
    "# Creating a mapping from unique characters to indices\n",
    "characters_to_idx = {u:i for i, u in enumerate(vocabulary)}\n",
    "idx_to_characters = {i:u for u, i in characters_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m\n",
       "\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0morigin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0muntar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmd5_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mfile_hash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_subdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mhash_algorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mextract\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0marchive_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Downloads a file from a URL if it not already in the cache.\n",
       "\n",
       "By default the file at the url `origin` is downloaded to the\n",
       "cache_dir `~/.keras`, placed in the cache_subdir `datasets`,\n",
       "and given the filename `fname`. The final location of a file\n",
       "`example.txt` would therefore be `~/.keras/datasets/example.txt`.\n",
       "\n",
       "Files in tar, tar.gz, tar.bz, and zip formats can also be extracted.\n",
       "Passing a hash will verify the file after download. The command line\n",
       "programs `shasum` and `sha256sum` can compute the hash.\n",
       "\n",
       "Arguments:\n",
       "    fname: Name of the file. If an absolute path `/path/to/file.txt` is\n",
       "        specified the file will be saved at that location.\n",
       "    origin: Original URL of the file.\n",
       "    untar: Deprecated in favor of 'extract'.\n",
       "        boolean, whether the file should be decompressed\n",
       "    md5_hash: Deprecated in favor of 'file_hash'.\n",
       "        md5 hash of the file for verification\n",
       "    file_hash: The expected hash string of the file after download.\n",
       "        The sha256 and md5 hash algorithms are both supported.\n",
       "    cache_subdir: Subdirectory under the Keras cache dir where the file is\n",
       "        saved. If an absolute path `/path/to/folder` is\n",
       "        specified the file will be saved at that location.\n",
       "    hash_algorithm: Select the hash algorithm to verify the file.\n",
       "        options are 'md5', 'sha256', and 'auto'.\n",
       "        The default 'auto' detects the hash algorithm in use.\n",
       "    extract: True tries extracting the file as an Archive, like tar or zip.\n",
       "    archive_format: Archive format to try for extracting the file.\n",
       "        Options are 'auto', 'tar', 'zip', and None.\n",
       "        'tar' includes tar, tar.gz, and tar.bz files.\n",
       "        The default 'auto' is ['tar', 'zip'].\n",
       "        None or an empty list will return no matches found.\n",
       "    cache_dir: Location to store cached files, when None it\n",
       "        defaults to the [Keras\n",
       "          Directory](/faq/#where-is-the-keras-configuration-filed-stored).\n",
       "\n",
       "Returns:\n",
       "    Path to the downloaded file\n",
       "\u001b[0;31mFile:\u001b[0m      ~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/data_utils.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "keras.utils.get_file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dickens_rnn.batch8.kerasmodel'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(\"https://storage.googleapis.com/tff-models-public/dickens_rnn.batch8.kerasmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_model(batch_size):\n",
    "    origin = f\"https://storage.googleapis.com/tff-models-public/dickens_rnn.batch{batch_size}.kerasmodel\"\n",
    "    fname = (os.path\n",
    "               .basename(origin))\n",
    "    path = (keras.utils\n",
    "                 .get_file(fname, origin))\n",
    "    keras_model = (keras.models\n",
    "                        .load_model(path, compile=False))\n",
    "    return keras_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string):\n",
    "    num_generate = 200\n",
    "    input_eval = [characters_to_idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    text_generated = []\n",
    "    temperature = 1.0\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        text_generated.append(idx_to_characters[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What of TensorFlow Federated, you ask? Then, what a corner of the d\n",
      "gentlemen,\" said Stryver, looking at the crowd; all\n",
      "was to warm as if he said it with his awith the hungred man\n",
      "with him, and because he had a light and time--\n",
      "\n",
      "The b\n"
     ]
    }
   ],
   "source": [
    "# Text generation requires a batch_size=1 model.\n",
    "pretrained_model_1 = load_pretrained_model(batch_size=1)\n",
    "print(generate_text(pretrained_model_1, 'What of TensorFlow Federated, you ask? '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Preprocess the Federated Shakespeare Data\n",
    "\n",
    "The [`tff.simulation.datasets`](https://www.tensorflow.org/federated/api_docs/python/tff/simulation/datasets) package provides a variety of datasets that are split into \"clients\", where each client corresponds to a dataset on a particular device that might participate in federated learning.\n",
    "\n",
    "These datasets provide realistic non-IID data distributions that replicate in simulation the challenges of training on real decentralized data. Some of the pre-processing of this data was done using tools from the [Leaf project](https://github.com/TalwalkarLab/leaf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tff-datasets-public/shakespeare.tar.bz2\n",
      "1851392/1848122 [==============================] - 3s 2us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pughdr/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    }
   ],
   "source": [
    "training_data, testing_data = (tff.simulation\n",
    "                                  .datasets\n",
    "                                  .shakespeare\n",
    "                                  .load_data())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets provided consist of a sequence of string Tensors, one for each line spoken by a particular character in a Shakespeare play. The client keys consist of the name of the play joined with the name of the character, so for example `MUCH_ADO_ABOUT_NOTHING_OTHELLO` corresponds to the lines for the character Othello in the play *Much Ado About Nothing*. \n",
    "\n",
    "Note that in a real federated learning scenario clients are never identified or tracked by ids but for simulation it is useful to work with keyed datasets.\n",
    "\n",
    "Here, for example, we can look at some data from *King Lear*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the play is \"The Tragedy of King Lear\" and the character is \"King\".\n",
    "client_dataset = training_data.create_tf_dataset_for_client(\"THE_TRAGEDY_OF_KING_LEAR_KING\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b\"Live regist'red upon our brazen tombs,\\nAnd then grace us in the disgrace of death;\\nWhen, spite of cormorant devouring Time,\\nTh' endeavour of this present breath may buy\\nThat honour which shall bate his scythe's keen edge,\\nAnd make us heirs of all eternity.\\nTherefore, brave conquerors- for so you are\\nThat war against your own affections\\nAnd the huge army of the world's desires-\\nOur late edict shall strongly stand in force:\\nNavarre shall be the wonder of the world;\\nOur court shall be a little Academe,\\nStill and contemplative in living art.\\nYou three, Berowne, Dumain, and Longaville,\\nHave sworn for three years' term to live with me\\nMy fellow-scholars, and to keep those statutes\\nThat are recorded in this schedule here.\\nYour oaths are pass'd; and now subscribe your names,\\nThat his own hand may strike his honour down\\nThat violates the smallest branch herein.\\nIf you are arm'd to do as sworn to do,\\nSubscribe to your deep oaths, and keep it too.\\nYour oath is pass'd to pass away from these.\", shape=(), dtype=string)\n",
      "tf.Tensor(b'this?\\nDid you hear the proclamation?', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# To allow for future extensions, each entry x\n",
    "# is an OrderedDict with a single key 'snippets' which contains the text.\n",
    "for x in client_dataset.take(2):\n",
    "    print(x['snippets'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use [`tf.data.Dataset`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) transformations to prepare this data for training the char RNN loaded above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = (tf.data\n",
    "              .experimental\n",
    "              .AUTOTUNE)\n",
    "SEQUENCE_LENGTH = 100\n",
    "SHUFFLE_BUFFER_SIZE = 10000\n",
    "NUMBER_TRAINING_EPOCHS = 3\n",
    "TRAINING_BATCH_SIZE = 8\n",
    "TESTING_BATCH_SIZE = 8\n",
    "\n",
    "# create the look-up table based on vocabulary\n",
    "_indices = tf.constant([n for n in range(len(vocabulary))], dtype=tf.int64) \n",
    "_initializer = (tf.lookup\n",
    "                  .KeyValueTensorInitializer(vocabulary, values=_indices))\n",
    "TABLE = (tf.lookup\n",
    "           .StaticHashTable(_initializer, default_value=-1))\n",
    "\n",
    "\n",
    "def _to_indices(entry):\n",
    "    snippets = tf.reshape(entry[\"snippets\"], shape=[1])\n",
    "    characters = (tf.strings\n",
    "                    .bytes_split(snippets)\n",
    "                    .values)\n",
    "    indices = TABLE.lookup(characters)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def _to_input_target(batch):\n",
    "    input_sequence = tf.map_fn(lambda x: x[:-1], batch)\n",
    "    target_sequence = tf.map_fn(lambda x: x[1:], batch)\n",
    "    return input_sequence, target_sequence\n",
    "\n",
    "\n",
    "def create_training_dataset(client_dataset,\n",
    "                            seed=None,\n",
    "                            num_parallel_calls=AUTOTUNE,\n",
    "                            shuffle_buffer_size=SHUFFLE_BUFFER_SIZE,\n",
    "                            number_epochs=NUMBER_TRAINING_EPOCHS,\n",
    "                            batch_size=TRAINING_BATCH_SIZE,\n",
    "                            prefetch_buffer_size=AUTOTUNE):\n",
    "    \"\"\"Create a training dataset from raw client dataset.\"\"\"\n",
    "    _dataset = (client_dataset.map(_to_indices, num_parallel_calls)\n",
    "                              .unbatch()\n",
    "                              .batch(SEQUENCE_LENGTH + 1, drop_remainder=True)\n",
    "                              .shuffle(shuffle_buffer_size, seed, reshuffle_each_iteration=True)\n",
    "                              .repeat(number_epochs)\n",
    "                              .batch(batch_size, drop_remainder=True)\n",
    "                              .map(_to_input_target)\n",
    "                              .prefetch(prefetch_buffer_size))\n",
    "    return _dataset\n",
    "\n",
    "\n",
    "def create_training_datasets(client_ids,\n",
    "                             seed=None,\n",
    "                             num_parallel_calls=AUTOTUNE,\n",
    "                             shuffle_buffer_size=SHUFFLE_BUFFER_SIZE,\n",
    "                             number_epochs=NUMBER_TRAINING_EPOCHS,\n",
    "                             batch_size=TRAINING_BATCH_SIZE,\n",
    "                             prefetch_buffer_size=AUTOTUNE):\n",
    "    \"\"\"Creates a TF Dataset for each client id.\"\"\"\n",
    "    training_datasets = []\n",
    "    for client_id in client_ids:\n",
    "        client_dataset = training_data.create_tf_dataset_for_client(client_id)\n",
    "        training_dataset = (create_training_dataset(client_dataset,\n",
    "                                                    seed,\n",
    "                                                    num_parallel_calls,\n",
    "                                                    shuffle_buffer_size,\n",
    "                                                    number_epochs,\n",
    "                                                    batch_size,\n",
    "                                                    prefetch_buffer_size))\n",
    "        training_datasets.append(training_dataset)\n",
    "    return training_datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the formation of the original sequences and in the formation of batches above, we use `drop_remainder=True` for simplicity. This means that any characters (clients) that don't have at least `(SEQ_LENGTH + 1) * BATCH_SIZE` chars of text will have empty datasets. There are many standard approaches to dealing with this issue, note however, that in the federated setting this issue is more significant because many users might have small datasets.\n",
    "\n",
    "Now we can preprocess our `client_dataset`, and check the types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_client_dataset = create_training_dataset(client_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(TensorSpec(shape=(8, 100), dtype=tf.int64, name=None), TensorSpec(shape=(8, 100), dtype=tf.int64, name=None))\n"
     ]
    }
   ],
   "source": [
    "print(preprocessed_client_dataset.element_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model and test on the preprocessed data\n",
    "\n",
    "We loaded an uncompiled keras model, but in order to run evaluate the model, we need to compile it with a loss and metrics. We will also compile in an optimizer, which will be used as the on-device optimizer in Federated Learning.\n",
    "\n",
    "The original tutorial didn't have char-level accuracy (the fraction of predictions where the highest probability was put on the correct next char). This is a useful metric, so we add it. However, we need to define a new metric class for this because our predictions have rank 3 (a vector of logits for each of the BATCH_SIZE * SEQ_LENGTH predictions), and SparseCategoricalAccuracy expects only rank 2 predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlattenedSparseCategoricalAccuracy(keras.metrics.SparseCategoricalAccuracy):\n",
    "\n",
    "    def __init__(self, name='accuracy', dtype=None):\n",
    "        super().__init__(name, dtype=dtype)\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_true = tf.reshape(y_true, [-1, 1])\n",
    "        y_pred = tf.reshape(y_pred, [-1, len(vocabulary), 1])\n",
    "        return super().update_state(y_true, y_pred, sample_weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_keras_model(model, optimizer):\n",
    "    _loss_fn = (keras.losses\n",
    "                     .SparseCategoricalCrossentropy(from_logits=True))\n",
    "    _metrics = [\n",
    "        FlattenedSparseCategoricalAccuracy()\n",
    "    ]\n",
    "    model.compile(\n",
    "        optimizer,\n",
    "        loss=_loss_fn,\n",
    "        metrics=_metrics\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on an example Shakespeare character:\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.1858 - accuracy: 0.4200\n",
      "\n",
      "Expected accuracy for random guessing: 0.012\n",
      "Evaluating on completely random data:\n",
      "1/1 [==============================] - 1s 777ms/step - loss: 11.4736 - accuracy: 0.0113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[11.473602294921875, 0.01125]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAINING_BATCH_SIZE = 8  # The training and eval batch size for the rest of this tutorial.\n",
    "\n",
    "model_fn = load_pretrained_model(batch_size=TRAINING_BATCH_SIZE)\n",
    "optimizer = keras.optimizers.SGD(lr=0.5)\n",
    "compile_keras_model(model_fn, optimizer)\n",
    "\n",
    "# Confirm that loss is much lower on Shakespeare than on random data\n",
    "print('Evaluating on an example Shakespeare character:')\n",
    "model_fn.evaluate(preprocessed_client_dataset.take(1))\n",
    "\n",
    "# As a sanity check, we can construct some completely random data, where we expect\n",
    "# the accuracy to be essentially random:\n",
    "random_indexes = np.random.randint(\n",
    "    low=0, high=len(vocabulary), size=1 * TRAINING_BATCH_SIZE * (SEQUENCE_LENGTH + 1))\n",
    "data = {\n",
    "    'snippets':\n",
    "        tf.constant(''.join(np.array(vocabulary)[random_indexes]), shape=[1, 1])\n",
    "}\n",
    "random_dataset = preprocess(tf.data.Dataset.from_tensor_slices(data))\n",
    "print('\\nExpected accuracy for random guessing: {:.3f}'.format(1.0 / len(vocabulary)))\n",
    "print('Evaluating on completely random data:')\n",
    "model_fn.evaluate(random_dataset, steps=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune the model with Federated Learning\n",
    "\n",
    "TFF serializes all TensorFlow computations so they can potentially be run in a non-Python environment (even though at the moment, only a simulation runtime implemented in Python is available). Even though we are running in eager mode, (TF 2.0), currently TFF serializes TensorFlow computations by constructing the necessary ops inside the context of a \"with tf.Graph.as_default()\" statement. Thus, we need to provide a function that TFF can use to introduce our model into a graph it controls. We do this as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the keras_model inside `create_tff_model()`, which TFF will\n",
    "# call to produce a new copy of the model inside the graph that it will serialize.\n",
    "def create_tff_model():\n",
    "    # TFF uses a `dummy_batch` so it knows the types and shapes\n",
    "    # that your model expects.\n",
    "    x = tf.constant(np.random.randint(1, len(vocabulary), size=[TRAINING_BATCH_SIZE, SEQUENCE_LENGTH]))\n",
    "    dummy_batch = collections.OrderedDict([('x', x), ('y', x)])\n",
    "    optimizer = keras.optimizers.SGD(lr=0.5)\n",
    "    cloned_model_fn = compile_keras_model(keras.models.clone_model(model_fn), optimizer)\n",
    "    return tff.learning.from_compiled_keras_model(cloned_model_fn, dummy_batch=dummy_batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to construct a Federated Averaging iterative process, which we will use to improve the model (for details on the Federated Averaging algorithm, see the paper Communication-Efficient Learning of Deep Networks from Decentralized Data).\n",
    "\n",
    "We use a compiled Keras model to perform standard (non-federated) evaluation after each round of federated training. This is useful for research purposes when doing simulated federated learning and there is a standard test dataset.\n",
    "\n",
    "In a realistic production setting this same technique might be used to take models trained with federated learning and evaluate them on a centralized benchmark dataset for testing or quality assurance purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This command builds all the TensorFlow graphs and serializes them: \n",
    "fed_avg = tff.learning.build_federated_averaging_process(model_fn=create_tff_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's write a slightly more interesting training and evaluation loop.\n",
    "\n",
    "So that this simulation still runs relatively quickly, we train on the same three clients each round, only considering two minibatches for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pughdr/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    }
   ],
   "source": [
    "def data(client, source=training_data):\n",
    "    return preprocess(source.create_tf_dataset_for_client(client)).take(2)\n",
    "\n",
    "clients = ['ALL_S_WELL_THAT_ENDS_WELL_CELIA',\n",
    "           'MUCH_ADO_ABOUT_NOTHING_OTHELLO',\n",
    "           'THE_TRAGEDY_OF_KING_LEAR_KING']\n",
    "\n",
    "train_datasets = [data(client) for client in clients]\n",
    "\n",
    "# We concatenate the test datasets for evaluation with Keras.\n",
    "test_dataset = functools.reduce(\n",
    "    lambda d1, d2: d1.concatenate(d2),\n",
    "    [data(client, testing_data) for client in clients]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating before training round 0\n",
      "2/2 [==============================] - 3s 2s/step - loss: 3.2486 - accuracy: 0.4000\n",
      "Training metrics:  <accuracy=0.4193750023841858,loss=3.228424072265625>\n",
      "Evaluating before training round 1\n",
      "2/2 [==============================] - 2s 944ms/step - loss: 3.0612 - accuracy: 0.4169\n",
      "Training metrics:  <accuracy=0.4397916793823242,loss=2.9016449451446533>\n",
      "Evaluating before training round 2\n",
      "2/2 [==============================] - 2s 843ms/step - loss: 2.6694 - accuracy: 0.4481\n",
      "Training metrics:  <accuracy=0.4660416543483734,loss=2.6546707153320312>\n",
      "Evaluating before training round 4\n",
      "2/2 [==============================] - 2s 1s/step - loss: 2.8271 - accuracy: 0.4256\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 3\n",
    "\n",
    "# The state of the FL server, containing the model and optimization state.\n",
    "state = fed_avg.initialize()\n",
    "\n",
    "state = tff.learning.state_with_new_model_weights(\n",
    "    state,\n",
    "    trainable_weights=[v.numpy() for v in model_fn.trainable_weights],\n",
    "    non_trainable_weights=[\n",
    "        v.numpy() for v in model_fn.non_trainable_weights\n",
    "    ])\n",
    "\n",
    "\n",
    "def keras_evaluate(state, round_num):\n",
    "    tff.learning.assign_weights_to_keras_model(model_fn, state.model)\n",
    "    print('Evaluating before training round', round_num)\n",
    "    model_fn.evaluate(preprocessed_client_dataset, steps=2)\n",
    "\n",
    "\n",
    "for round_num in range(NUM_ROUNDS):\n",
    "    keras_evaluate(state, round_num)\n",
    "    # N.B. The TFF runtime is currently fairly slow,\n",
    "    # expect this to get significantly faster in future releases.\n",
    "    state, metrics = fed_avg.next(state, train_datasets)\n",
    "    print('Training metrics: ', metrics)\n",
    "\n",
    "keras_evaluate(state, NUM_ROUNDS + 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x136d20ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function zero_all_if_any_non_finite at 0x136d20ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pughdr/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/simulation/hdf5_client_data.py:69: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  collections.OrderedDict((name, ds.value) for name, ds in sorted(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-d52c831cf57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# perform the federated computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfederated_averaging_process\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfederated_training_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"round:{n}, metrics:{metrics}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/utils/function_utils.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m     \u001b[0marg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, fn, arg)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mcomputed_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_comp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0mpy_typecheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComputedValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m       type_utils.check_assignable_from(comp.type_signature.result,\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    810\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mComputationContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m     return ComputedValue(lambda x: self._compute(comp.result, _wrap(x)),\n\u001b[0m\u001b[1;32m    813\u001b[0m                          comp.type_signature)\n\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, comp, context)\u001b[0m\n\u001b[1;32m    723\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_lambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilding_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBlock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilding_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntrinsic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_intrinsic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m_compute_block\u001b[0;34m(self, comp, context)\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0mpy_typecheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComputationContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlocal_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_comp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m       \u001b[0mlocal_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_comp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m       \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComputationContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlocal_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlocal_val\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m_compute\u001b[0;34m(self, comp, context)\u001b[0m\n\u001b[1;32m    713\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_compiled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilding_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCall\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilding_blocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m_compute_call\u001b[0;34m(self, comp, context)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mcomputed_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputed_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m     \u001b[0mpy_typecheck\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mComputedValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m     type_utils.check_assignable_from(computed_fn.type_signature.result,\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0marg_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_signature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         return ComputedValue(\n\u001b[0;32m--> 840\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmy_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_argument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m             comp.type_signature)\n\u001b[1;32m    842\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m_federated_map\u001b[0;34m(self, arg)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     result_val = [\n\u001b[0;32m--> 884\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComputedValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m     ]\n\u001b[1;32m    886\u001b[0m     result_type = computation_types.FederatedType(mapping_type.result,\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m     result_val = [\n\u001b[0;32m--> 884\u001b[0;31m         \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mComputedValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m     ]\n\u001b[1;32m    886\u001b[0m     result_type = computation_types.FederatedType(mapping_type.result,\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    743\u001b[0m           'but found \\'{}\\' instead.'.format(computation_oneof))\n\u001b[1;32m    744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m       return ComputedValue(lambda x: run_tensorflow(comp, x),\n\u001b[0m\u001b[1;32m    746\u001b[0m                            comp.type_signature)\n\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/reference_executor.py\u001b[0m in \u001b[0;36mrun_tensorflow\u001b[0;34m(comp, arg)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minit_op\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m       \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m     \u001b[0mresult_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensorflow_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_value_in_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m   return capture_computed_value_from_graph(result_val,\n\u001b[1;32m    345\u001b[0m                                            comp.type_signature.result)\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_federated/python/core/impl/utils/tensorflow_utils.py\u001b[0m in \u001b[0;36mfetch_value_in_session\u001b[0;34m(sess, value)\u001b[0m\n\u001b[1;32m   1069\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported value type {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m     \u001b[0mflat_computed_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     flattened_results = _interleave_dataset_results_and_tensors(\n\u001b[1;32m   1073\u001b[0m         dataset_results, flat_computed_tensors)\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Training/data-science-project-templates/tensorflow-federated-data-science-project/env/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 5\n",
    "RANDOM_STATE = np.random.RandomState(42)\n",
    "\n",
    "federated_averaging_process = (tff.learning\n",
    "                                  .build_federated_averaging_process(create_tff_model))\n",
    "state = federated_averaging_process.initialize()\n",
    "\n",
    "\n",
    "def sample_client_ids(client_ids: list,\n",
    "                      sample_size: float,\n",
    "                      random_state: np.random.RandomState) -> list:\n",
    "    \"\"\"Randomly selects a subset of clients ids.\"\"\"\n",
    "    n_clients = len(client_ids)\n",
    "    n_clients_per_sample = int(sample_size * n_clients)\n",
    "    random_indices = random_state.randint(n_clients, size=n_clients_per_sample)\n",
    "    return [client_ids[i] for i in random_indices]\n",
    "\n",
    "\n",
    "for n in range(NUM_ROUNDS):\n",
    "    \n",
    "    # resample 1% of all clients at each round\n",
    "    client_ids = sample_client_ids(training_data.client_ids, 0.01, RANDOM_STATE)\n",
    "    federated_training_data = create_training_datasets(client_ids)\n",
    "\n",
    "    # perform the federated computation\n",
    "    state, metrics = federated_averaging_process.next(state, federated_training_data)\n",
    "    print(f\"round:{n}, metrics:{metrics}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggested extensions\n",
    "\n",
    "This tutorial is just the first step! Here are some ideas for how you might try extending this notebook: \n",
    "\n",
    "* Write a more realistic training loop where you sample clients to train on randomly.\n",
    "* Use \".repeat(NUM_EPOCHS)\" on the client datasets to try multiple epochs of local training (e.g., as in McMahan et. al.). See also Federated Learning for Image Classification which does this. \n",
    "* Change the compile() command to experiment with using different optimization algorithms on the client. \n",
    "* Try the server_optimizer argument to build_federated_averaging_process to try different algorithms for applying the model updates on the server. \n",
    "* Try the client_weight_fn argument to to build_federated_averaging_process to try different weightings of the clients. The default weights client updates by the number of examples on the client, but you can do e.g. client_weight_fn=lambda _: tf.constant(1.0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
